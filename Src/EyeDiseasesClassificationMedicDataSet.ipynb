{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "I5jYo6pXcc4m"
      },
      "source": [
        "# Imports\n",
        "\n",
        "* May be needed to install some modules in our python enviroment - here are some of the modules This project does need to run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POLjIgARcc4w",
        "outputId": "b0c05368-8119-4b5e-b2c3-df491c3ea950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Invalid requirement: '#'\n"
          ]
        }
      ],
      "source": [
        "# uncomment the following lines if you need to install any of the modules described below\n",
        "# %pip install --upgrade pip    # pip, model for package management\n",
        "# %pip install tensorflow       # tensorflow, model knowed for deep learning\n",
        "# %pip install seaborn          # seaborn, model for data visualization\n",
        "# %pip install matplotlib       # matplotlib, model for data visualization\n",
        "# %pip install opencv-python    # opencv-python, model for image processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWXLoUhPd9s4",
        "outputId": "b98e03a6-1eb3-4141-af19-ebd2fb3980a1"
      },
      "outputs": [],
      "source": [
        "using_Colab = False\n",
        "\n",
        "if using_Colab:\n",
        "  !git clone https://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@github.com/mariana73154/OcularDiseasesClassification.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hpV5-EWUcc4z"
      },
      "outputs": [],
      "source": [
        "import numpy as np                  # numpy, model for data manipulation  \n",
        "import pandas as pd                 # pandas, model for data manipulation\n",
        "import os, random                   # os, model for operating system\n",
        "import matplotlib.pyplot as plt     # matplotlib, model for data visualization\n",
        "import seaborn as sns               # seaborn, model for data visualization\n",
        "import tensorflow as tf             # tensorflow, model knowed for deep learning\n",
        "import keras                        # keras, model knowed for deep learning\n",
        "\n",
        "# other keras imports\n",
        "from keras.preprocessing import image   # image, model for image processing\n",
        "from keras.models import Sequential     # Sequential, model for deep learning\n",
        "# keras layers\n",
        "from keras.layers import  Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization, Activation, GlobalAveragePooling2D, Input                               \n",
        "from keras.preprocessing.image import ImageDataGenerator # ImageDataGenerator, model for image processing\n",
        "from keras.applications import VGG16, InceptionResNetV2, ResNet50, Xception  # VGG16, InceptionResNetV2, RESNet model for deep learning    \n",
        "from keras import regularizers                           # regularizers, model for deep learning\n",
        "from keras.optimizers import Adam,RMSprop,SGD,Adamax     # Adam,RMSprop,SGD,Adamax, model for deep learning\n",
        "from keras.models import Model                           # Model, model for deep learning\n",
        "from keras import layers                                 # layers, model for deep learning\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping # ReduceLROnPlateau, EarlyStopping, model for deep learning"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "O5IZtl8Kcc40"
      },
      "source": [
        "# Problem and Data\n",
        "\n",
        "Whit this notebook I pretend to use deep learning in order to classified diferent type of eye diseases. As of any deep learning model it needs data to train and lean from it. IÂ´ve searched for data in sites such as the well knowed Kaggle and Google datasets. \n",
        "In this case the dataset I will use will be mainly the one from kaggle : https://www.kaggle.com/datasets/gunavenkatdoddi/eye-diseases-classification.\n",
        "\n",
        "Dataset is stored in \"Data\" folder and is composed of:\n",
        "\n",
        "* 1038 images of eyes with cataracts\n",
        "* 1098 images of eyes with diabetic retinopathy\n",
        "* 1007 images of eyed with glaucoma\n",
        "* 1074 images of healthy eyes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMvYD9dtcc41",
        "outputId": "02bbf6cc-906f-4512-a00e-52c33884cf4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of images in the [ GLAUCOMA ] :  2819\n",
            "Total number of images in the [ NORMAL ] :  11312\n",
            "Total number of images in the [ DATASET ] : 14131\n"
          ]
        }
      ],
      "source": [
        "# count number of files in a directory\n",
        "def count_files(directory):\n",
        "    return len([item for item in os.listdir(directory) if os.path.isfile(os.path.join(directory, item))])\n",
        "\n",
        "EyeDiseases = dict()\n",
        "DatasetPath = '/content/OcularDiseasesClassification/Data/dataset/' if using_Colab else 'D:/Datase_retina_brasil_Jose/Data/'\n",
        "\n",
        "for dir in os.listdir(DatasetPath):\n",
        "    print('Total number of images in the [', dir.upper() ,'] : ', count_files(DatasetPath + dir))\n",
        "    EyeDiseases.update({dir:count_files(DatasetPath + dir)} )\n",
        "\n",
        "print('Total number of images in the [ DATASET ] :', sum(EyeDiseases.values()))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mGdaGd7wcc42"
      },
      "source": [
        "The dataset has four equally distributed classes.\n",
        "However, 4000 images may not be sufficient, so I will create synthetic images using data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "bq7X5F2gcc42",
        "outputId": "e6600232-b9b4-44a2-df38-c149662ae7f0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Plot the number of images in each class using a pie chart\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.pie(EyeDiseases.values(), labels=EyeDiseases.keys(), autopct='%1.1f%%', startangle=90)\n",
        "plt.title('Number of images in each class')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz_qb2KXcc44"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Function to load images from the dataset folder\n",
        "def get_data(path_folder):\n",
        "    #Load the images from the folder \"dataset\" into train and test sets using ImageDataGenerator\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        path_folder,\n",
        "        target_size=(256, 256),\n",
        "        batch_size=20,\n",
        "        class_mode='categorical',\n",
        "        subset='training',\n",
        "        seed=10\n",
        "    )\n",
        "\n",
        "    validation_generator = train_datagen.flow_from_directory(\n",
        "        path_folder,\n",
        "        target_size=(256, 256),\n",
        "        batch_size=20,\n",
        "        class_mode='categorical',\n",
        "        subset='validation',\n",
        "        seed=10\n",
        "    )\n",
        "\n",
        "    return train_generator, validation_generator"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Function to get model\n",
        "#model_list = models list available\n",
        "#model_name = model name to get\n",
        "def get_model(model_list,model_name,weigths=None):\n",
        "\n",
        "    model = model_list[model_name](weigths)\n",
        "\n",
        "    #Summary of the model\n",
        "    model.summary()\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Function to train model\n",
        "#model = model to train\n",
        "#train_generator = train data\n",
        "#validation_generator = validation data\n",
        "#epochs = number of epochs to train\n",
        "\n",
        "def train_model(model,train_generator,validation_generator,epochs):\n",
        "    #Hyperparameters\n",
        "    #epochs=epochs\n",
        "\n",
        "    #Train the model\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=validation_generator,\n",
        "        epochs=epochs,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Function to evaluate model\n",
        "#history = history of the model\n",
        "\n",
        "def evaluate_model(history):\n",
        "\n",
        "    #Plot the training and validation accuracy and loss at each epoch\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    return plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Function to save model\n",
        "#model = model to save\n",
        "#model_name = model name to save\n",
        "#history = history of the model\n",
        "\n",
        "def save_model(model,model_name,history):\n",
        "\n",
        "    #Create a folder to save models if it does not exist\n",
        "    if not os.path.exists('Saved_Models'):\n",
        "        os.mkdir('Saved_Models')\n",
        "    \n",
        "    #Create a folder to save the model if it does not exist\n",
        "    if not os.path.exists('Saved_Models/'+ model_name):\n",
        "        os.mkdir('Saved_Models/'+ model_name)\n",
        "    \n",
        "    #Save the model\n",
        "    model.save('Saved_Models/'+ model_name +'/'+ model_name +'.h5')\n",
        "\n",
        "    #Save the evaluation of model\n",
        "    plt = evaluate_model(history)\n",
        "    plt.savefig('Saved_Models/'+ model_name +'/'+ model_name +'_evaluation.png')\n",
        "\n",
        "    #Save the model architecture\n",
        "    tf.keras.utils.plot_model(\n",
        "        model,\n",
        "        to_file='Saved_Models/'+ model_name +'/'+ model_name +'.png',\n",
        "        show_shapes=True,\n",
        "        show_layer_names=True,\n",
        "    )\n",
        "\n",
        "    #Save the model history into a csv \n",
        "    hist_df = pd.DataFrame(history.history)\n",
        "    hist_csv_file = 'Saved_Models/'+ model_name +'/'+ model_name +'_history.csv'\n",
        "    with open(hist_csv_file, mode='w') as f:\n",
        "        hist_df.to_csv(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Function to load Model\n",
        "#model_list = models list available\n",
        "#path_folder = path to load model\n",
        "#model_name = model name to load\n",
        "def Run_Model(model_list,path_folder,model_name, weights = None):\n",
        "        #Get data\n",
        "        train_generator, validation_generator = get_data(path_folder)\n",
        "    \n",
        "        #Get model\n",
        "        model = get_model(model_list,model_name)\n",
        "    \n",
        "        #Train model\n",
        "        model, history = train_model(model,train_generator,validation_generator,epochs=30)\n",
        "    \n",
        "        #Evaluate model\n",
        "        evaluate_model(history)\n",
        "    \n",
        "        #Save model\n",
        "        save_model(model,model_name,history)\n",
        "    \n",
        "        return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CNN "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Function of architecture of CNN model\n",
        "def CNN_model(weights=None):\n",
        "    #Create a CNN model\n",
        "    model = Sequential()\n",
        "\n",
        "    #Input Layer\n",
        "    Inputlayer = Input(shape=(256, 256, 3))\n",
        "\n",
        "    # 1st Convolutional Layer\n",
        "    x = Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(Inputlayer)\n",
        "    x = Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(x)\n",
        "    x = MaxPool2D(pool_size=(2,2))(x)\n",
        "\n",
        "    # 2nd Convolutional Layer\n",
        "    x = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(x)\n",
        "    x = MaxPool2D(pool_size=(2,2))(x)\n",
        "\n",
        "    # 3rd Convolutional Layer\n",
        "    x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(x)\n",
        "    x = MaxPool2D(pool_size=(2,2))(x)\n",
        "\n",
        "    # Output Layer\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=128, activation='relu')(x)\n",
        "    x = Dropout(rate=0.2)(x)\n",
        "    x = Dense(units=2, activation='softmax')(x)\n",
        "\n",
        "    # Model\n",
        "    model = Model(inputs=Inputlayer, outputs=x)\n",
        "    return model    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jLhis34Gcc45"
      },
      "outputs": [],
      "source": [
        "#Function of architecture of VGG16 model\n",
        "def VGG16_model(weights=None):\n",
        "    #Create a VGG16 model\n",
        "    model = Sequential()\n",
        "\n",
        "    #Input Layer\n",
        "    Inputlayer = Input(shape=(256, 256, 3))\n",
        "    \n",
        "    # Importing VGG16 from keras API\n",
        "    x=VGG16(include_top=False, weights=weights, input_shape=(256,256,3))(Inputlayer)\n",
        "\n",
        "    # Output Layer\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=128, activation='relu')(x)\n",
        "    x = Dropout(rate=0.2)(x)\n",
        "    x = Dense(units=2, activation='softmax')(x)\n",
        "\n",
        "    # Model\n",
        "    model = Model(inputs=Inputlayer, outputs=x)\n",
        "    return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RESNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Function of architecture of RESNet model\n",
        "def RESNet_model(weights=None):\n",
        "    #Create a VGG16 model\n",
        "    model = Sequential()\n",
        "\n",
        "    #Input Layer\n",
        "    Inputlayer = Input(shape=(256, 256, 3))\n",
        "\n",
        "    # Importing RESNet from keras API without weights\n",
        "    x=ResNet50(include_top=False, weights=weights, input_shape=(256,256,3))(Inputlayer)\n",
        "    \n",
        "    # Output Layer\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=128, activation='relu')(x)\n",
        "    x = Dropout(rate=0.2)(x)\n",
        "    x = Dense(units=2, activation='softmax')(x)\n",
        "\n",
        "    # Model\n",
        "    model = Model(inputs=Inputlayer, outputs=x)\n",
        "    return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Function of architecture of Xception model\n",
        "def Xception_model(weights=None):\n",
        "    #Create a VGG16 model\n",
        "    model = Sequential()\n",
        "\n",
        "    #Input Layer\n",
        "    Inputlayer = Input(shape=(256, 256, 3))\n",
        "\n",
        "    # Importing Xception from keras API without weights\n",
        "    x=Xception(include_top=False, weights=weights, input_shape=(256,256,3))(Inputlayer)\n",
        "    \n",
        "    # Output Layer\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=128, activation='relu')(x)\n",
        "    x = Dropout(rate=0.2)(x)\n",
        "    x = Dense(units=2, activation='softmax')(x)\n",
        "\n",
        "    # Model\n",
        "    model = Model(inputs=Inputlayer, outputs=x)\n",
        "    return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## List Of Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List off available Models - defined above\n",
        "model_list = { \n",
        "    \"CNN_model\":CNN_model , \n",
        "    \"VGG16_model\" : VGG16_model ,\n",
        "    \"RESNet_model\" : RESNet_model ,\n",
        "    \"Xception_model\" : Xception_model ,\n",
        "}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run all models"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Run_Model(model_list,DatasetPath,\"CNN_model\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Without weights\n",
        "Run_Model(model_list,DatasetPath,\"VGG16_model\", weights = None)\n",
        "#With weights\n",
        "Run_Model(model_list,DatasetPath,\"VGG16_model\", weights = 'imagenet')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RESNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Without weights\n",
        "Run_Model(model_list,DatasetPath,\"RESNet_model\", weights = None)\n",
        "#With weights\n",
        "Run_Model(model_list,DatasetPath,\"RESNet_model\", weights = 'imagenet')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Without weights\n",
        "Run_Model(model_list,DatasetPath,\"Xception_model\", weights = None)\n",
        "#With weights\n",
        "Run_Model(model_list,DatasetPath,\"Xception_model\", weights = 'imagenet')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save models in zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the models in a zip file -- use this in colab to download the models\n",
        "!zip -r /content/saved_models.zip /content/saved_models"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
